{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model for the project (Gemini 2.0 with added RAG)\n",
    "The workflow here was influenced by a popular article (https://masteringllm.medium.com/best-practices-for-rag-pipeline-8c12a8096453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pypdf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "load_dotenv(dotenv_path=Path('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pdfs if not done yet\n",
    "path = './pdfs'\n",
    "pdfs = os.listdir(path)\n",
    "is_pdf_merged = False\n",
    "merged_pdf_path = \"\"\n",
    "\n",
    "def merge_pdf(path, pdfs):\n",
    "    merged_pdf = pypdf.PdfWriter()\n",
    "    pdf_paths = [os.path.join(path, pdf) for pdf in pdfs \n",
    "                 if re.search('Air', pdf)]\n",
    "    \n",
    "    for pdf in pdf_paths:        \n",
    "        merged_pdf.append(pdf)\n",
    "        os.remove(pdf)\n",
    "    \n",
    "    merged_pdf_path = os.path.join(path, \"Air-Quality-Factors.pdf\")\n",
    "    merged_pdf.write(merged_pdf_path)\n",
    "\n",
    "\n",
    "for i, pdf in enumerate(pdfs):\n",
    "    if pdf == \"Air-Quality-Factors.pdf\":\n",
    "        is_pdf_merged = True\n",
    "        break\n",
    "    elif (i == len(pdfs)-1) and (is_pdf_merged == False):\n",
    "        merge_pdf(path, pdfs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Air-Quality-Factors.pdf', 'Bombatronic - Dataset.pdf', 'How Fire Incidents Happen.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4615/838399379.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 86 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "new_documents = []\n",
    "\n",
    "# Set the new list of pdfs after removing the unmerged files\n",
    "pdfs = os.listdir(path)\n",
    "pdfs_path = [os.path.join(path, pdf) for pdf in pdfs]\n",
    "pdfs_name = [pdf for pdf in pdfs]\n",
    "print(pdfs_name)\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', api_key=api_key)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(google_api_key=api_key, model='models/embedding-001')\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"bombatronic_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "def load_pdfs(pdf_file, pdf_name, i):\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 100,\n",
    "        chunk_overlap = 50,\n",
    "        length_function = len,\n",
    "        is_separator_regex= False\n",
    "    )\n",
    "\n",
    "    doc_split = text_splitter.split_documents(pages)\n",
    "\n",
    "    # Set the document metadatas id and source (whilst removing the .pdf)\n",
    "    for doc in doc_split:\n",
    "        doc.metadata = {\n",
    "            \"id\": i,\n",
    "            \"title\": re.sub('.pdf', '', pdf_name)\n",
    "    }\n",
    "        \n",
    "    existing_metadata = vector_store.get(\n",
    "        where={\"title\": re.sub('.pdf', '', pdf_name)}\n",
    "    )\n",
    "    \n",
    "    # print(existing_metadata)\n",
    "    for key, value in existing_metadata.items():\n",
    "\n",
    "        # Set new documents if the value of the metadata hasnt been established\n",
    "        if (key == 'metadatas' and value == []):\n",
    "            new_documents.extend(doc_split) \n",
    "\n",
    "for i, pdf in enumerate(pdfs_path):\n",
    "    load_pdfs(pdf, pdfs_name[i], i)\n",
    "\n",
    "# print(new_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(documents):\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "    vector_store.add_documents(documents=documents, ids=uuids)\n",
    "\n",
    "if  (new_documents != []):\n",
    "    # Store new documents if theres any\n",
    "    store_embeddings(new_documents)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "def is_rag_needed(input_text):\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an LLM that would specialize in answering \"\n",
    "        \"questions related to Air Quality Index and its parameters, whilst also\"\n",
    "        \"posessing a strong knowledge on Fire Cases worldwide, how to mitigate them, and \"\n",
    "        \"the solution behind it if the user were to have a question surrounding it\"),\n",
    "        (\"user\", \"I posses additional information about Air Quality, Fire Incidents, and\"\n",
    "        \"a team called Bombatronic, do you think based on my question here can it help\"\n",
    "        \"you to get a better understanding of my question, which is, {input} , also JUST ANSWER\"\n",
    "        \"AS IN YES OR NO, do not answer anything besides YES or NO\")\n",
    "    ])\n",
    "    chain = prompt | llm | output_parser\n",
    "    response = chain.invoke({\"input\": input_text})\n",
    "    return response.lower()\n",
    "\n",
    "input_text = str(input())\n",
    "rag_state = is_rag_needed(input_text=input_text)\n",
    "print(rag_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot Invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air-Quality-Factors <class 'str'>\n",
      "[Document(metadata={'id': 0, 'title': 'Air-Quality-Factors'}, page_content='Carbon  monoxide  and  carbon  dioxide  significantly  impact  air  quality,  each  through'), Document(metadata={'id': 0, 'title': 'Air-Quality-Factors'}, page_content='Carbon  Monoxide  (CO)  and  Carbon  Dioxide  (CO2)  effects  on  Air  Quality   1.  Definition'), Document(metadata={'id': 0, 'title': 'Air-Quality-Factors'}, page_content='influences\\n \\nair\\n \\nquality.\\n \\nRising\\n \\nCO\\nâ‚‚\\n \\nlevels\\n \\ncontribute\\n \\nto\\n \\nglobal\\n \\nwarming,')]\n",
      "Carbon monoxide (CO) significantly impacts air quality due to its toxic nature. It's a colorless, odorless gas produced by the incomplete combustion of fossil fuels and other carbon-containing materials. When inhaled, CO interferes with the blood's ability to carry oxygen, leading to various health problems, especially for individuals with heart disease, pregnant women, and young children. High concentrations of CO in the air can result in reduced oxygen delivery to vital organs, causing symptoms ranging from headaches and dizziness to unconsciousness and even death. Therefore, monitoring and controlling CO levels are crucial for maintaining good air quality and protecting public health.\n"
     ]
    }
   ],
   "source": [
    "def chatbot_response(input_text, rag_state, input_metadata):\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an LLM that would specialize in answering \"\n",
    "        \"questions related to Air Quality Index and its parameters, whilst also\"\n",
    "        \"posessing a strong knowledge on Fire Cases worldwide, how to mitigate them, and \"\n",
    "        \"the solution behind it if the user were to have a question surrounding it. Also you need\"\n",
    "        \"to possess an additional information about the team BOMBATRONIC when askes about it thats\"\n",
    "        \"given from the context by the user. Keep your answer to the question in a paragaph like \"\n",
    "        \"format and make it sweet and intuitive\"),\n",
    "        (\"user\", \"{input}\\n\\n: {context}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | output_parser\n",
    "    if rag_state == \"yes\":\n",
    "        print(input_metadata[0], type(input_metadata[0]))\n",
    "        retrieved_docs = vector_store.similarity_search(\n",
    "            query=input_text,\n",
    "            k=3,\n",
    "            filter={\"title\": input_metadata[0]} if input_metadata else None\n",
    "        )\n",
    "        print(retrieved_docs)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    response = chain.invoke({\"input\": input_text, \"context\": context})\n",
    "\n",
    "    return response\n",
    "\n",
    "key_and_metadata = {\n",
    "    \"air\": \"Air-Quality-Factors\",\n",
    "    \"fire\": \"How Fire Incidents Happen\",\n",
    "    \"bombatronic\": \"Bombatronic - Dataset\"\n",
    "}\n",
    "\n",
    "input_metadata = [md for key, md in key_and_metadata.items() if re.search(key, input_text.lower())]\n",
    "\n",
    "response = chatbot_response(input_text, rag_state, input_metadata)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_keywords</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what carbon monoxide?</td>\n",
       "      <td>Carbon monoxide, colorless, odorless, incomple...</td>\n",
       "      <td>Air-Quality-Factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what carbon dioxide?</td>\n",
       "      <td>Carbon dioxide, greenhouse gas, natural proces...</td>\n",
       "      <td>Air-Quality-Factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What factors behind fire incident?</td>\n",
       "      <td>Electrical malfunctions, faulty wiring, overlo...</td>\n",
       "      <td>How Fire Incidents Happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How mitigate indoor fires public places?</td>\n",
       "      <td>Regular inspections, maintenance, electrical s...</td>\n",
       "      <td>How Fire Incidents Happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apa bombatronic?</td>\n",
       "      <td>Bombatronic, alat pemadam api otomatis, AI, co...</td>\n",
       "      <td>Bombatronic - Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0                     what carbon monoxide?   \n",
       "1                      what carbon dioxide?   \n",
       "2        What factors behind fire incident?   \n",
       "3  How mitigate indoor fires public places?   \n",
       "4                          Apa bombatronic?   \n",
       "\n",
       "                                     answer_keywords  \\\n",
       "0  Carbon monoxide, colorless, odorless, incomple...   \n",
       "1  Carbon dioxide, greenhouse gas, natural proces...   \n",
       "2  Electrical malfunctions, faulty wiring, overlo...   \n",
       "3  Regular inspections, maintenance, electrical s...   \n",
       "4  Bombatronic, alat pemadam api otomatis, AI, co...   \n",
       "\n",
       "                    metadata  \n",
       "0        Air-Quality-Factors  \n",
       "1        Air-Quality-Factors  \n",
       "2  How Fire Incidents Happen  \n",
       "3  How Fire Incidents Happen  \n",
       "4      Bombatronic - Dataset  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple evaluation tests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_eval = pd.read_csv('./eval.csv')\n",
    "df_eval.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similiarity between all answers (based on keywords): 11.55%\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "def jaccard_similarity(true, pred):\n",
    "    # print(f\"True answer: {true}\\nPred answer: {pred}\\n\")\n",
    "    true_set = set(true)\n",
    "    pred_set = set(pred)\n",
    "\n",
    "    intersection = true_set.intersection(pred_set)\n",
    "    union = true_set.union(pred_set)\n",
    "\n",
    "    similarity = len(intersection) / len(union)\n",
    "    # print(similarity)\n",
    "    return similarity\n",
    "\n",
    "def evaluation_invoking(df):\n",
    "    answers = []\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an LLM that would specialize in answering \"\n",
    "        \"questions related to Air Quality Index and its parameters, whilst also\"\n",
    "        \"posessing a strong knowledge on Fire Cases worldwide, how to mitigate them, and \"\n",
    "        \"the solution behind it if the user were to have a question surrounding it. Also you need\"\n",
    "        \"to possess an additional information about the team BOMBATRONIC when asked about it thats\"\n",
    "        \"given from the context by the user. Keep your answer to the question in a paragaph like \"\n",
    "        \"format and make it sweet and intuitive.\"),\n",
    "        (\"user\", \"{input}\\n\\n: {context}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    for _, rows in df.iterrows():\n",
    "        question = rows[\"question\"]\n",
    "        # print(question)\n",
    "        # print(rows[\"metadata\"])\n",
    "        metadata = rows[\"metadata\"]\n",
    "        # print(metadata)\n",
    "        retrieved_docs = vector_store.similarity_search(\n",
    "            query=question,\n",
    "            k=1,\n",
    "            filter={\"title\": metadata}\n",
    "        )\n",
    "        # print(retrieved_docs)\n",
    "        # print(f\"DOCS Retrieved: {retrieved_docs}\\n\")\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        response = chain.invoke({\"input\": question, \"context\": context})\n",
    "        # print(f\"Chatbot Response: {response}\")\n",
    "        answers.append(response)\n",
    "\n",
    "    return answers\n",
    "\n",
    "answers = evaluation_invoking(df_eval)\n",
    "\n",
    "for i in range(len(answers)):\n",
    "    true_answer = df_eval[\"answer_keywords\"][i].split(\" \")\n",
    "    pred_answer = answers[i].split(\" \")\n",
    "\n",
    "    true_lowered = list(map(lambda x: x.lower(), true_answer))\n",
    "    pred_lowered = list(map(lambda x: x.lower(), pred_answer))\n",
    "\n",
    "    # print(f\"{true_lowered}\\n{pred_lowered}\")\n",
    "    true_cleaned = list(map(lambda x: re.sub(r'\\,|\\-', '', x), true_lowered))\n",
    "    pred_cleaned = list(map(lambda x: re.sub(r'\\,|\\-', '', x), pred_lowered))\n",
    "\n",
    "    sim_result = jaccard_similarity(true_cleaned, pred_cleaned)\n",
    "    similarity.append(sim_result)\n",
    "\n",
    "results = np.mean(similarity)\n",
    "print(f\"Mean similiarity between all answers (based on keywords): {(results * 100):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
